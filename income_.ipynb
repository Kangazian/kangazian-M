{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d333515a",
   "metadata": {},
   "source": [
    "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "درآمد\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed20bff",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مقدمه و صورت مسئله\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این تمرین قصد داریم درخت تصمیمی بسازیم که قادر باشد با دریافت یک سری ویژگی‌های شخصی و شغلی از شهروندان آمریکایی پیش‌بینی کند آیا شخص درآمد سالانه‌ی بالای ۵۰ هزار دلار خواهد داشت یا خیر. مجموعه‌داده‌ی مورداستفاده و صورت مسئله بسیار خوش‌تعریف است، با این حال جهت پیش‌پردازش مناسب ویژگی‌ها و همچنین دست‌یابی به یک مدل  با عملکرد بالا نیاز است از تکنیک‌های مختلف مهندسی ویژگی و فوت‌و‌فن‌های مرتبط با درخت تصمیم که در درسنامه‌ها آموخته‌اید استفاده کنید. بهره‌گیری از این تکنیک‌ها جهت مواجهه با چالش‌های عملی می‌تواند به‌خوبی شما را برای استفاده از این مدل در دنیای واقعی آماده کند.‌\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1784",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "وارد کردن کتابخانه‌های مورد نیاز\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ابتدا کتابخانه‌های مورد نیازتان را وارد کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72faaed8",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    هر نمونه از این مجموعه‌داده با ویژگی‌هایی که در جدول زیر شرح داده شده همراه است. ستون <code>income</code> متغیر هدف مسئله است که درآمد شخص را نشان می‌دهد. \n",
    "</font>\n",
    "</p>\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|age|سن|\n",
    "|workclass|یک عبارت کلی که نشان‌دهنده‌ی وضعیت شغلی فرد است.|\n",
    "|fnlwgt|وزن نهایی، به عبارت دیگر تعداد افرادی که سرشماری باور دارد این ردیف بازنمایی می‌کند (نماینده‌ی آنهاست). |\n",
    "|education|بیشترین سطح تحصیلات فرد |\n",
    "|education.num|بیشترین سطح تحصیلات فرد به شکل عددی |\n",
    "|marital.status|وضعیت تاهل فرد. توجه شود که <code>Married-­civ-­spouse</code> به معنی همسر غیرنظامی و <code>Married-­AF-­spouse</code> به معنی همسر نظامی است.|\n",
    "|occupation|نوع کلی شغل یک فرد |\n",
    "|relationship|رابطه‌ی این فرد با دیگران، به عنوان مثال همسر (<code>Husband</code>). هر داده تنها دارای یک رابطه است. |\n",
    "|race|نژاد |\n",
    "|sex| جنسیت بیولوژیکی فرد |\n",
    "|capital.gain|سود سرمایه‌ی فرد  |\n",
    "|capital.loss| زیان سرمایه‌ی فرد |\n",
    "|hours.per.week| ساعت‌هایی که فرد گزارش داده در یک هفته کار می‌کند. |\n",
    "|native.country| سرزمین مادری |\n",
    "|income|درآمد، کمتر یا مساوی ۵۰ هزار دلار (<code dir=ltr><=50K</code>) یا بیشتر از آن (<code dir=ltr>>50K</code>) |\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e99bbe9b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در ابتدا نیاز است فایل‌های مجموعه‌داده را بخوانید. نمونه‌های آموزشی در فایل <code>train.csv</code> و نمونه‌های آزمون که باید دسته‌ی آن‌ها را پیش‌بینی کنید در فایل <code>test.csv</code> ذخیره شده‌اند. اگر لازم دانستید می‌توانید به دلخواه خود بخشی از مجموعه‌ی آموزشی را به عنوان مجموعه‌ی اعتبارسنجی نیز جدا کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>?</td>\n",
       "      <td>148657</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>130834</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>31</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>33124</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>190895</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>420973</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>88055</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt     education  education.num  \\\n",
       "0       40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1       30           Private  149118       HS-grad              9   \n",
       "2       46           Private  109209  Some-college             10   \n",
       "3       32           Private  229566     Assoc-voc             11   \n",
       "4       54                 ?  148657     Preschool              1   \n",
       "...    ...               ...     ...           ...            ...   \n",
       "24995   40           Private  130834  Some-college             10   \n",
       "24996   31         Local-gov   33124     Bachelors             13   \n",
       "24997   38       Federal-gov  190895     Bachelors             13   \n",
       "24998   23           Private  420973     Bachelors             13   \n",
       "24999   60           Private   88055          10th              6   \n",
       "\n",
       "           marital.status        occupation   relationship   race     sex  \\\n",
       "0      Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "1                Divorced      Craft-repair  Not-in-family  White  Female   \n",
       "2      Married-civ-spouse      Adm-clerical        Husband  White    Male   \n",
       "3      Married-civ-spouse     Other-service        Husband  White    Male   \n",
       "4      Married-civ-spouse                 ?           Wife  White  Female   \n",
       "...                   ...               ...            ...    ...     ...   \n",
       "24995       Never-married      Adm-clerical  Not-in-family  White  Female   \n",
       "24996       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24997  Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "24998       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24999  Married-civ-spouse  Transport-moving        Husband  White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0             99999             0              70  United-States   >50K  \n",
       "1                 0             0              40  United-States  <=50K  \n",
       "2                 0             0              40  United-States   >50K  \n",
       "3                 0             0              60  United-States   >50K  \n",
       "4                 0             0              40         Mexico  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "24995             0             0              40  United-States  <=50K  \n",
       "24996             0             0              50  United-States  <=50K  \n",
       "24997             0             0              40              ?   >50K  \n",
       "24998             0             0              40  United-States  <=50K  \n",
       "24999             0             0              40  United-States  <=50K  \n",
       "\n",
       "[25000 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb6ba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>176711</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>120277</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>299197</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>188260</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>254211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>37</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>75050</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>156780</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>381153</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>294395</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>24</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>506329</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7164 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age         workclass  fnlwgt     education  education.num  \\\n",
       "0      31           Private  176711       HS-grad              9   \n",
       "1      40           Private  120277  Some-college             10   \n",
       "2      43           Private  299197  Some-college             10   \n",
       "3      70      Self-emp-inc  188260       HS-grad              9   \n",
       "4      51           Private  254211     Bachelors             13   \n",
       "...   ...               ...     ...           ...            ...   \n",
       "7159   37  Self-emp-not-inc   75050     Assoc-voc             11   \n",
       "7160   36           Private  156780       HS-grad              9   \n",
       "7161   34           Private  381153       HS-grad              9   \n",
       "7162   59           Private  294395       Masters             14   \n",
       "7163   24         State-gov  506329  Some-college             10   \n",
       "\n",
       "          marital.status        occupation    relationship  \\\n",
       "0     Married-civ-spouse  Transport-moving         Husband   \n",
       "1          Never-married             Sales   Not-in-family   \n",
       "2     Married-civ-spouse      Adm-clerical         Husband   \n",
       "3     Married-civ-spouse   Exec-managerial         Husband   \n",
       "4     Married-civ-spouse      Craft-repair         Husband   \n",
       "...                  ...               ...             ...   \n",
       "7159  Married-civ-spouse      Craft-repair         Husband   \n",
       "7160       Never-married             Sales  Other-relative   \n",
       "7161  Married-civ-spouse  Transport-moving         Husband   \n",
       "7162             Widowed    Prof-specialty   Not-in-family   \n",
       "7163       Never-married      Adm-clerical       Own-child   \n",
       "\n",
       "                    race     sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0                  White    Male             0             0              38   \n",
       "1                  White    Male             0             0              40   \n",
       "2                  White    Male             0             0              40   \n",
       "3                  White    Male             0             0              16   \n",
       "4                  White    Male             0             0              20   \n",
       "...                  ...     ...           ...           ...             ...   \n",
       "7159               White    Male             0             0              55   \n",
       "7160  Asian-Pac-Islander  Female             0             0              40   \n",
       "7161               White    Male             0             0              40   \n",
       "7162               White  Female             0             0              40   \n",
       "7163  Asian-Pac-Islander    Male             0             0              40   \n",
       "\n",
       "     native.country  \n",
       "0     United-States  \n",
       "1     United-States  \n",
       "2     United-States  \n",
       "3     United-States  \n",
       "4     United-States  \n",
       "...             ...  \n",
       "7159  United-States  \n",
       "7160              ?  \n",
       "7161  United-States  \n",
       "7162  United-States  \n",
       "7163              ?  \n",
       "\n",
       "[7164 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data =pd.read_csv('test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23daec54",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "پیش‌پردازش و مهندسی ویژگی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در این سوال شما می‌توانید از هر تکنیک پیش‌پردازش/مهندسی ویژگی که در فصل‌های گذشته آموختید، استفاده کنید. توجه داشته باشید که انتخاب شما در بخش بعدی یعنی مدل‌سازی می‌تواند مراحلی که در این بخش طی می‌کنید را تحت تاثیر قرار دهد. بنابراین پیشنهاد می‌کنیم مواردی همچون مدیریت مقادیر گم‌شده، ویژگی‌های دسته‌ای و غیره را پس از مطالعه‌ی بخش بعد انجام دهید.\n",
    "    <br>\n",
    "    تکنیک‌هایی که در این بخش استفاده می‌کنید به شکل مستقیم مورد ارزیابی توسط سامانه داوری قرار <b>نمی‌گیرند.</b> بلکه همه آن‌ها در دقت مدل شما تاثیر خواهند گذاشت؛ بنابراین هر چه پیش‌پردازش/مهندسی ویژگی بهتری انجام دهید تا دقت مدل بهبود پیدا کند، امتیاز بیشتری از این سوال کسب خواهید کرد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2f4f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148657</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>130834</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>31</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>33124</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>190895</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>420973</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>88055</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt     education  education.num  \\\n",
       "0       40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1       30           Private  149118       HS-grad              9   \n",
       "2       46           Private  109209  Some-college             10   \n",
       "3       32           Private  229566     Assoc-voc             11   \n",
       "4       54               NaN  148657     Preschool              1   \n",
       "...    ...               ...     ...           ...            ...   \n",
       "24995   40           Private  130834  Some-college             10   \n",
       "24996   31         Local-gov   33124     Bachelors             13   \n",
       "24997   38       Federal-gov  190895     Bachelors             13   \n",
       "24998   23           Private  420973     Bachelors             13   \n",
       "24999   60           Private   88055          10th              6   \n",
       "\n",
       "           marital.status        occupation   relationship   race     sex  \\\n",
       "0      Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "1                Divorced      Craft-repair  Not-in-family  White  Female   \n",
       "2      Married-civ-spouse      Adm-clerical        Husband  White    Male   \n",
       "3      Married-civ-spouse     Other-service        Husband  White    Male   \n",
       "4      Married-civ-spouse               NaN           Wife  White  Female   \n",
       "...                   ...               ...            ...    ...     ...   \n",
       "24995       Never-married      Adm-clerical  Not-in-family  White  Female   \n",
       "24996       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24997  Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "24998       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24999  Married-civ-spouse  Transport-moving        Husband  White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0             99999             0              70  United-States   >50K  \n",
       "1                 0             0              40  United-States  <=50K  \n",
       "2                 0             0              40  United-States   >50K  \n",
       "3                 0             0              60  United-States   >50K  \n",
       "4                 0             0              40         Mexico  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "24995             0             0              40  United-States  <=50K  \n",
       "24996             0             0              50  United-States  <=50K  \n",
       "24997             0             0              40            NaN   >50K  \n",
       "24998             0             0              40  United-States  <=50K  \n",
       "24999             0             0              40  United-States  <=50K  \n",
       "\n",
       "[25000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data.replace('?',np.nan)\n",
    "test_data=test_data.replace('?',np.nan)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff62a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1429\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education.num        0\n",
       "marital.status       0\n",
       "occupation        1434\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital.gain         0\n",
       "capital.loss         0\n",
       "hours.per.week       0\n",
       "native.country     437\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f694c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "workclass         387\n",
       "fnlwgt              0\n",
       "education           0\n",
       "education.num       0\n",
       "marital.status      0\n",
       "occupation        389\n",
       "relationship        0\n",
       "race                0\n",
       "sex                 0\n",
       "capital.gain        0\n",
       "capital.loss        0\n",
       "hours.per.week      0\n",
       "native.country    138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20571b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>223881</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>149118</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>109209</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>229566</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>148657</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>130834</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>31</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>33124</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>190895</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>420973</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>88055</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt     education  education.num  \\\n",
       "0       40  Self-emp-not-inc  223881   Prof-school             15   \n",
       "1       30           Private  149118       HS-grad              9   \n",
       "2       46           Private  109209  Some-college             10   \n",
       "3       32           Private  229566     Assoc-voc             11   \n",
       "4       54           Private  148657     Preschool              1   \n",
       "...    ...               ...     ...           ...            ...   \n",
       "24995   40           Private  130834  Some-college             10   \n",
       "24996   31         Local-gov   33124     Bachelors             13   \n",
       "24997   38       Federal-gov  190895     Bachelors             13   \n",
       "24998   23           Private  420973     Bachelors             13   \n",
       "24999   60           Private   88055          10th              6   \n",
       "\n",
       "           marital.status        occupation   relationship   race     sex  \\\n",
       "0      Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "1                Divorced      Craft-repair  Not-in-family  White  Female   \n",
       "2      Married-civ-spouse      Adm-clerical        Husband  White    Male   \n",
       "3      Married-civ-spouse     Other-service        Husband  White    Male   \n",
       "4      Married-civ-spouse    Prof-specialty           Wife  White  Female   \n",
       "...                   ...               ...            ...    ...     ...   \n",
       "24995       Never-married      Adm-clerical  Not-in-family  White  Female   \n",
       "24996       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24997  Married-civ-spouse    Prof-specialty        Husband  White    Male   \n",
       "24998       Never-married    Prof-specialty  Not-in-family  White  Female   \n",
       "24999  Married-civ-spouse  Transport-moving        Husband  White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0             99999             0              70  United-States   >50K  \n",
       "1                 0             0              40  United-States  <=50K  \n",
       "2                 0             0              40  United-States   >50K  \n",
       "3                 0             0              60  United-States   >50K  \n",
       "4                 0             0              40         Mexico  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "24995             0             0              40  United-States  <=50K  \n",
       "24996             0             0              50  United-States  <=50K  \n",
       "24997             0             0              40  United-States   >50K  \n",
       "24998             0             0              40  United-States  <=50K  \n",
       "24999             0             0              40  United-States  <=50K  \n",
       "\n",
       "[25000 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling missing data by Mode method\n",
    "missing_columns=train_data.columns[train_data.isna().sum()>0]\n",
    "for i in missing_columns:\n",
    "\n",
    "    train_data[i]=train_data[i].fillna(train_data[i].mode()[0])\n",
    "    test_data[i]=test_data[i].fillna(test_data[i].mode()[0])\n",
    "\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f08a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "income            0\n",
      "dtype: int64 Nan_number Duplicated_number =  12\n"
     ]
    }
   ],
   "source": [
    "NAN_number=train_data.isna().sum()\n",
    "Duplicated_number=train_data.duplicated().sum()\n",
    "print(NAN_number,'Nan_number','Duplicated_number = ',Duplicated_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbe3907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24988, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data.drop_duplicates()\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f69a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24988 entries, 0 to 24999\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             24988 non-null  int64 \n",
      " 1   workclass       24988 non-null  object\n",
      " 2   fnlwgt          24988 non-null  int64 \n",
      " 3   education       24988 non-null  object\n",
      " 4   education.num   24988 non-null  int64 \n",
      " 5   marital.status  24988 non-null  object\n",
      " 6   occupation      24988 non-null  object\n",
      " 7   relationship    24988 non-null  object\n",
      " 8   race            24988 non-null  object\n",
      " 9   sex             24988 non-null  object\n",
      " 10  capital.gain    24988 non-null  int64 \n",
      " 11  capital.loss    24988 non-null  int64 \n",
      " 12  hours.per.week  24988 non-null  int64 \n",
      " 13  native.country  24988 non-null  object\n",
      " 14  income          24988 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b785876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629d037b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24988, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outlaiyer\n",
    "from scipy import stats\n",
    "numerica_col=train_data.select_dtypes(include=[np.number])\n",
    "df_c=train_data[(np.abs(stats.zscore(numerica_col))<3).all(axis=1)]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ca0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data['income']=train_data['income'].replace({'<=50K':0 ,'>50K':1})\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\2512655978.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['income']=train_data['income'].replace({'<=50K':0 ,'>50K':1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>223881</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>149118</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>109209</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>229566</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>148657</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>130834</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>33124</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>190895</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>420973</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>88055</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24988 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education.num  marital.status  \\\n",
       "0       40          5  223881         14             15               2   \n",
       "1       30          3  149118         11              9               0   \n",
       "2       46          3  109209         15             10               2   \n",
       "3       32          3  229566          8             11               2   \n",
       "4       54          3  148657         13              1               2   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "24995   40          3  130834         15             10               4   \n",
       "24996   31          1   33124          9             13               4   \n",
       "24997   38          0  190895          9             13               2   \n",
       "24998   23          3  420973          9             13               4   \n",
       "24999   60          3   88055          0              6               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital.gain  capital.loss  \\\n",
       "0               9             0     4    1         99999             0   \n",
       "1               2             1     4    0             0             0   \n",
       "2               0             0     4    1             0             0   \n",
       "3               7             0     4    1             0             0   \n",
       "4               9             5     4    0             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "24995           0             1     4    0             0             0   \n",
       "24996           9             1     4    0             0             0   \n",
       "24997           9             0     4    1             0             0   \n",
       "24998           9             1     4    0             0             0   \n",
       "24999          13             0     4    1             0             0   \n",
       "\n",
       "       hours.per.week  native.country  income  \n",
       "0                  70              37       1  \n",
       "1                  40              37       0  \n",
       "2                  40              37       1  \n",
       "3                  60              37       1  \n",
       "4                  40              24       0  \n",
       "...               ...             ...     ...  \n",
       "24995              40              37       0  \n",
       "24996              50              37       0  \n",
       "24997              40              37       1  \n",
       "24998              40              37       0  \n",
       "24999              40              37       0  \n",
       "\n",
       "[24988 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorica_col=train_data.iloc[:,:-1].select_dtypes(include=['object']).columns.to_list()\n",
    "categorica_col\n",
    "for j in categorica_col:\n",
    "    train_data[j]=LabelEncoder().fit_transform(train_data[j])\n",
    "    test_data[j]=LabelEncoder().fit_transform(test_data[j])\n",
    "    \n",
    "train_data['income']=train_data['income'].replace({'<=50K':0 ,'>50K':1})\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "099c21d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24988 entries, 0 to 24999\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   age             24988 non-null  int64\n",
      " 1   workclass       24988 non-null  int32\n",
      " 2   fnlwgt          24988 non-null  int64\n",
      " 3   education       24988 non-null  int32\n",
      " 4   education.num   24988 non-null  int64\n",
      " 5   marital.status  24988 non-null  int32\n",
      " 6   occupation      24988 non-null  int32\n",
      " 7   relationship    24988 non-null  int32\n",
      " 8   race            24988 non-null  int32\n",
      " 9   sex             24988 non-null  int32\n",
      " 10  capital.gain    24988 non-null  int64\n",
      " 11  capital.loss    24988 non-null  int64\n",
      " 12  hours.per.week  24988 non-null  int64\n",
      " 13  native.country  24988 non-null  int32\n",
      " 14  income          24988 non-null  int64\n",
      "dtypes: int32(8), int64(7)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bb5cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.31506849 0.17808219 0.39726027 ... 0.28767123 0.08219178 0.5890411 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.71428571 0.42857143 0.42857143 ... 0.         0.42857143 0.42857143]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.14370628 0.09293069 0.06582633 ... 0.1213037  0.27756211 0.0514595 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.93333333 0.73333333 1.         ... 0.6        0.6        0.        ]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.93333333 0.53333333 0.6        ... 0.8        0.8        0.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.33333333 0.         0.33333333 ... 0.33333333 0.66666667 0.33333333]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.69230769 0.15384615 0.         ... 0.69230769 0.69230769 1.        ]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.  0.2 0.  ... 0.  0.2 0. ]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1. 1. 1. ... 1. 1. 1.]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.70408163 0.39795918 0.39795918 ... 0.39795918 0.39795918 0.39795918]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.94871795 0.94871795 0.94871795 ... 0.94871795 0.94871795 0.94871795]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.19178082 0.31506849 0.35616438 ... 0.23287671 0.57534247 0.09589041]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.42857143 0.42857143 0.42857143 ... 0.42857143 0.42857143 0.85714286]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.11167058 0.0733432  0.19485745 ... 0.25051819 0.19159615 0.33553198]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.73333333 1.         1.         ... 0.73333333 0.8        1.        ]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.53333333 0.6        0.6        ... 0.53333333 0.86666667 0.6       ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.33333333 0.66666667 0.33333333 ... 0.33333333 1.         0.66666667]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.         0.84615385 0.         ... 1.         0.69230769 0.        ]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.  0.2 0.  ... 0.  0.2 0.6]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.   1.   1.   ... 1.   1.   0.25]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.37755102 0.39795918 0.39795918 ... 0.39795918 0.39795918 0.39795918]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_8240\\383522327.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.97435897 0.97435897 0.97435897 ... 0.97435897 0.97435897 0.97435897]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.143706</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.065826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.147567</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.092618</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.080513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.014153</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121304</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.277562</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.051460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24988 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education.num  \\\n",
       "0      0.315068   0.714286  0.143706   0.933333       0.933333   \n",
       "1      0.178082   0.428571  0.092931   0.733333       0.533333   \n",
       "2      0.397260   0.428571  0.065826   1.000000       0.600000   \n",
       "3      0.205479   0.428571  0.147567   0.533333       0.666667   \n",
       "4      0.506849   0.428571  0.092618   0.866667       0.000000   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "24995  0.315068   0.428571  0.080513   1.000000       0.600000   \n",
       "24996  0.191781   0.142857  0.014153   0.600000       0.800000   \n",
       "24997  0.287671   0.000000  0.121304   0.600000       0.800000   \n",
       "24998  0.082192   0.428571  0.277562   0.600000       0.800000   \n",
       "24999  0.589041   0.428571  0.051460   0.000000       0.333333   \n",
       "\n",
       "       marital.status  occupation  relationship  race  sex  capital.gain  \\\n",
       "0            0.333333    0.692308           0.0   1.0    1           1.0   \n",
       "1            0.000000    0.153846           0.2   1.0    0           0.0   \n",
       "2            0.333333    0.000000           0.0   1.0    1           0.0   \n",
       "3            0.333333    0.538462           0.0   1.0    1           0.0   \n",
       "4            0.333333    0.692308           1.0   1.0    0           0.0   \n",
       "...               ...         ...           ...   ...  ...           ...   \n",
       "24995        0.666667    0.000000           0.2   1.0    0           0.0   \n",
       "24996        0.666667    0.692308           0.2   1.0    0           0.0   \n",
       "24997        0.333333    0.692308           0.0   1.0    1           0.0   \n",
       "24998        0.666667    0.692308           0.2   1.0    0           0.0   \n",
       "24999        0.333333    1.000000           0.0   1.0    1           0.0   \n",
       "\n",
       "       capital.loss  hours.per.week  native.country  income  \n",
       "0               0.0        0.704082        0.948718       1  \n",
       "1               0.0        0.397959        0.948718       0  \n",
       "2               0.0        0.397959        0.948718       1  \n",
       "3               0.0        0.602041        0.948718       1  \n",
       "4               0.0        0.397959        0.615385       0  \n",
       "...             ...             ...             ...     ...  \n",
       "24995           0.0        0.397959        0.948718       0  \n",
       "24996           0.0        0.500000        0.948718       0  \n",
       "24997           0.0        0.397959        0.948718       1  \n",
       "24998           0.0        0.397959        0.948718       0  \n",
       "24999           0.0        0.397959        0.948718       0  \n",
       "\n",
       "[24988 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "train_data.iloc[:,:-1]=scaler.fit_transform(train_data.iloc[:,:-1])\n",
    "test_data.iloc[:,:]=scaler.transform(test_data.iloc[:,:])\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2c94",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل‌سازی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال که داده را پاکسازی کرده و احتمالا ویژگی‌هایی را به آن افزوده یا از آن حذف کرده‌اید، وقت آن است که مدلی آموزش دهید که بتواند متغیر هدف این مسئله را پیش‌بینی کند. در این تمرین انتخاب کتابخانه‌ای که درخت تصمیم را در اختیارتان بگذارد به عهده‌ی خود شماست. می‌توانید همچون همیشه از کتابخانه‌ی <code>scikit-learn</code> استفاده کنید اما توجه داشته باشید که درخت تصمیم این کتابخانه از قابلیت‌های مهمی مثل مدیریت مستقیم مقادیر گم‌شده و ویژگی‌های دسته‌ای پشتیبانی نمی‌کند و نیاز خواهید داشت که مراحل پیش‌پردازش مختلفی را انجام دهید. اما پیشنهاد بهتر این است که با توجه به توضیحاتی که در ادامه خواهیم داد از کتابخانه‌ی <code>H2O</code> استفاده کنید که از قابلیت‌های ذکرشده پشتیبانی می‌کند و نیازی به طی کردن مراحل اضافی نیست (البته معمولاً عملکرد درخت تصمیم این کتابخانه هم بهتر از درخت تصمیم <code>scikit-learn</code> است). با این حال ما مقدار آستانه‌ی پاس شدن این تمرین را به‌گونه‌ای تنظیم کرده‌ایم که متعادل باشد و با هر دو روش بتوانید امتیاز موردنظر را کسب کنید. حتی می‌توانید خفن‌تر (😎) عمل کرده و با هرکدام از کتابخانه‌ها درخت تصمیمی بسازید و عملکرد آن‌ها را مقایسه کنید. \n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccbf48",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    استفاده از <code>scikit-learn</code>\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    به منظور استفاده از درخت تصمیم برای مسائل دسته‌بندی می‌توانید از <code>DecisionTreeClassifier</code> موجود در کتابخانه‌ی <code>scikit-learn</code> استفاده کنید. نحوه‌ی آموزش مدل و پیش‌بینی برای نمونه‌های جدید همچون تمام مدل‌های این کتابخانه است، اما برخی پارامترها و آرگومان‌های بسیار کاربردی این کلاس در جدول زیر شرح داده شده‌اند. جهت بررسی پارامترها و توضیحات بیشتر می‌توانید از <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\" target=\"__blank\">این لینک</a>، سند اصلی آن را مطالعه کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<p dir=ltr style=\"direction: ltr; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    <code dir=ltr>from sklearn.tree import DecisionTreeClassifier</code>\n",
    "    <br>\n",
    "    <code dir=ltr>clf = DecisionTreeClassifier()</code>\n",
    "</font>\n",
    "</p>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|پارامتر|توضیحات|مقادیر ممکن|مقدار پیش‌فرض|\n",
    "|:------:|:---:|:---:|:---:|\n",
    "|<code>criterion</code>|معیار ارزیابی تفکیک (معیار ناخالصی یا بهره اطلاعاتی)|<code>\"gini\"</code>، <code>\"entropy\"</code> یا <code>\"log_loss\"</code>|<code>\"gini\"</code>|\n",
    "|<code>max_depth</code>|حداکثر عمق درخت|عدد <code>int</code>|<code>None</code>|\n",
    "|<code>min_samples_split</code>|حداقل نمونه‌ها جهت تفکیک یک گره‌ی داخلی|عدد <code>int</code> (تعداد) یا <code>float</code> (درصد)|<code>2</code>|\n",
    "|<code>min_samples_leaf</code>|حداقل نمونه‌های یک برگ. یک گره تنها در صورتی تفکیک می‌یابد که هرکدام از شاخه‌های راست و چپ آن حداقل شامل این تعداد نمونه باشد|عدد <code>int</code> (تعداد) یا <code>float</code> (درصد)|<code>1</code>|\n",
    "|<code>max_features</code>|تعداد ویژگی‌هایی که در هنگام جستجوی بهترین تفکیک بررسی می‌شوند|عدد <code>int</code> (تعداد)، <code>float</code> (درصد)، ، <code>\"sqrt\"</code> (جذر)، <code>\"log2\"</code> (لگاریتم در مبنای ۲) یا <code>None</code> (تمام ویژگی‌ها)|<code>None</code>|\n",
    "|<code>min_impurity_decrease</code>|یک گره هنگامی تفکیک می‌شود که آن تفکیک باعث کاهش ناخالصی بیشتر یا مساوی این مقدار شود|عدد <code>float</code>|<code>0.0</code>|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    <b>نکته:</b>\n",
    "    پارامتر کاربردی دیگری به نام <code>ccp_alpha</code> وجود دارد که به منظور پس‌هرس درخت تصمیم با روش Minimal Cost-Complexity استفاده می‌شود. از آنجا که شرح این تکنیک خارج از بحث این فصل است، ضرورتی بر استفاده از آن تعریف نشده است. اما در صورت علاقه می‌توانید برای مطالعه‌ی این روش جذاب به بخش <a href=\"https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning\" target=\"__blank\">معرفی آن</a> در <code>scikit-learn</code> یا فصل سوم کتاب <i>Classification and Regression Trees</i> نوشته‌ی <i>Leo Breiman</i> مراجعه کرده و یا به شکلی ساده‌تر و جذاب‌تر <a href=\"https://youtu.be/D0efHEJsfHo\" target=\"__blank\">این ویدیو</a> را از <i>StatQuest</i> مشاهده کنید.  \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اگر مدل را <code>clf</code> بنامیم، پس از آموزش آن می‌توانید به کمک توابع یا متغیرهای زیر، برخی ویژگی‌های مهم درخت تصمیم را مورد بررسی قرار دهید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|پارامتر|توضیحات|\n",
    "|:------:|:---:|\n",
    "| <code dir=ltr>clf.get_depth()</code> | عمق درخت |\n",
    "| <code dir=ltr>clf.get_n_leaves()</code> | تعداد برگ‌های درخت |\n",
    "| <code dir=ltr>clf.feature_names_in_</code> | ویژگی‌های ورودی |\n",
    "| <code dir=ltr>clf.feature_importances_</code> | اهمیت هر ویژگی طبق معیار ناخالصی |\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    همچنین طبق کد زیر می‌توانید به کمک تابع <code>plot_tree</code> درخت تصمیم خود را ترسیم کنید. البته در صورتی‌که درخت حاصل بزرگ باشد ترسیم آن چندان جالب به نظر نخواهد رسید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<p dir=ltr style=\"direction: ltr; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    <code dir=ltr>from sklearn import tree</code>\n",
    "    <br>\n",
    "    <code dir=ltr>tree.plot_tree(clf)</code>\n",
    "</font>\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43db0ea",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"direction: rtl;text-align: right;line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    استفاده از <code>H2O</code>\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در کتابخانه‌ی <code>H2O</code> درخت تصمیم به‌صورت مشخص پیاده‌سازی نشده اما به کمک ترفندی که شرح خواهیم داد می‌توانید به یک درخت تصمیم دست یابید. در این کتابخانه مدل‌های حرفه‌ای‌تری پیاده‌سازی شده که در واقع اساس آن‌ها درخت تصمیم است. یکی از این مدل‌ها «<i>جنگل تصادفی</i>» نام دارد که در این کتابخانه با نام <code>H2ORandomForestEstimator</code> در دسترس است و در فصل یادگیری تجمعی کاملاً با ساختار آن آشنا خواهید شد. این مدل در واقع متشکل از تعداد زیادی درخت تصمیم است. بنابراین اگر ما یک جنگل تصادفی بسازیم که تنها شامل یک درخت باشد  در واقع مدل همانند یک درخت تصمیم عمل خواهد کرد. البته نیاز است به شکل زیر برخی از پارامترهای آن را به گونه‌ای مقداردهی کنیم که رفتاری شبیه به درخت تصمیم داشته باشد.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<p dir=ltr style=\"direction: ltr; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "<code>from h2o.estimators import H2ORandomForestEstimator</code>\n",
    "<br>\n",
    "<code>model = H2ORandomForestEstimator(ntrees=1, sample_rate=1)</code>\n",
    "</font>\n",
    "</p>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برخی از پارامترهای کاربردی این کلاس نیز در جدول زیر معرفی و شرح داده شده است. جهت بررسی پارامترها و توضیحات بیشتر می‌توانید از <a href=\"https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html\" target=\"__blank\">این لینک</a>، سند اصلی آن را مطالعه کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|پارامتر|توضیحات|مقادیر ممکن|مقدار پیش‌فرض|\n",
    "|:------:|:-----:|:---:|:---:|\n",
    "|<code>mtries</code>|تعداد ویژگی‌هایی که به‌صورت تصادفی در هر سطح برای جستجوی بهترین تفکیک استفاده می‌شود| <code dir=ltr>-1</code> برای جذر، <code dir=ltr>-2</code> برای تمام ویژگی‌ها یا عدد بزرگتر یا مساوی <code>1</code> |<code dir=ltr>-1</code>|\n",
    "|<code>max_depth</code>|حداکثر عمق درخت|عدد <code>int</code>|<code>20</code>|\n",
    "|<code>min_rows</code>|حداقل نمونه‌های یک برگ. یک گره تنها در صورتی تفکیک می‌یابد که هرکدام از شاخه‌های راست و چپ آن حداقل شامل این تعداد نمونه باشد|عدد <code>int</code>|<code>1</code>|\n",
    "|<code>min_split_improvement</code>|یک گره هنگامی تفکیک می‌شود که کاهش مربعات خطا حداقل به این میزان بهبود یابد|عدد کوچک (پیشنهاد می‌شود در بازه‌ی <code>1e-10</code> تا <code>1e-3</code> باشد)|<code>1e-05</code>|\n",
    "|<code>categorical_encoding</code>|رویکرد مدیریت ویژگی‌های دسته‌ای|<code>\"auto\"</code> (به‌صورت پیش‌فرض معادل <code>\"enum\"</code>)، <code>\"enum\"</code> (پشتیبانی مستقیم از ویژگی دسته‌ای)، <code>\"one_hot_explicit\"</code> (کدگذاری one-hot)،  <code>\"binary\"</code> (کدگذاری باینری)، <code>\"label_encoder\"</code> (برچسب‌گذاری) و غیره|<code>\"auto\"</code>|\n",
    "|<code>balance_classes</code>|متوازن‌سازی مجموعه‌داده به کمک نمونه‌افزایی کلاس اقلیت|<code>True</code> یا <code>False</code>|<code>False</code>|\n",
    "|<code>nfolds</code>|تعداد قطعه‌ها در اعتبارسنجی متقاطع (cross-validation)|عدد <code>int</code>|<code>0</code>|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای استفاده از <code>H2O</code> پیش از هرچیز نیاز است مراحل راه‌اندازی آن را که در درسنامه‌ی مربوط به این کتابخانه شرح داده شد اجرا کرده باشید و همچنین دیتافریم‌های خود را به <code>H2OFrame</code> تبدیل کرده باشید. پس از آن می‌توانید به کمک مدل معرفی‌شده در بالا پارامترهای موردنظر خود را مقداردهی کنید. سپس جهت آموزش مدل نیاز است تابع <code dir=ltr>fit()</code> را با سه آرگومان مهم زیر صدا بزنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|پارامتر|توضیحات|\n",
    "|:------:|:-----:|\n",
    "|<code>x</code>| لیستی شامل نام ستون‌های ورودی (ویژگی‌ها) |\n",
    "|<code>y</code>| نام ستون متغیر هدف |\n",
    "|<code>training_frame</code>| داده‌های آموزشی از جنس <code>H2OFrame</code> |\n",
    "|<code>validation_frame</code>| داده‌های اعتبارسنجی از جنس <code>H2OFrame</code> (دلخواه)|\n",
    "\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    جهت پیش‌بینی نیز می‌توانید <code>H2OFrame</code> موردنظر خود را به تابع <code dir=ltr>predict()</code> بدهید تا مدل شروع به پیش‌بینی متغیر هدف برای نمونه‌های موردنظر شما کند. توجه داشته باشید که اگر قصد دارید مقادیر پیش‌بینی‌شده را به یک دیتافریم <code>pandas</code> تبدیل کنید می‌توانید از تابع <code dir=ltr>as_data_frame()</code> استفاده کنید. مقادیر پیش‌بینی‌شده در ستونی به نام <code>predict</code> در دیتافریم به‌دست‌آمده ذخیره شده‌اند. \n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90b4d9",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "آموزش مدل\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    اکنون وقت آن رسیده که با توجه به کتابخانه‌ی انتخابی، مدل را آموزش دهید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c31dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Method\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X=train_data.drop(['income'],axis=1)\n",
    "Y=train_data['income']\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion='gini',max_depth=3, min_samples_split=2,min_samples_leaf=1 ,random_state=42)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da5d2a",
   "metadata": {},
   "source": [
    "<h3 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معیار ارزیابی\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    معیاری که برای ارزیابی عملکرد مدل انتخاب کرده‌ایم، <code>F1-score</code> نام دارد و کلاس مثبت (<code>pos_label</code>) را معادل <code dir=ltr>>50K</code> فرض کرده‌ایم، به این معنی که مدل شما باید برای پیش‌بینی درست افراد پردرآمد عملکرد مناسبی داشته باشد.\n",
    "    <br>\n",
    "    پیشنهاد می‌شود با توجه به این معیار، عملکرد مدل خود را بر روی مجموعه‌ی آموزش یا اعتبارسنجی ارزیابی کنید و طبق نتایج به‌دست‌آمده پارامترهای مدل خود را بهتر تنظیم کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee1b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score (weighted) = 0.82781753448316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      3840\n",
      "           1       0.74      0.48      0.58      1158\n",
      "\n",
      "    accuracy                           0.84      4998\n",
      "   macro avg       0.80      0.71      0.74      4998\n",
      "weighted avg       0.83      0.84      0.83      4998\n",
      "\n",
      "Confision_Matrix\n",
      "[[3648  192]\n",
      " [ 603  555]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate model of Clf\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "f1=f1_score(y_test,y_pred,average='weighted')\n",
    "classification_report=classification_report(y_test,y_pred)\n",
    "print('F1_Score (weighted) =' , f1)\n",
    "\n",
    "print(classification_report)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confision_Matrix')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad09cf",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    " جهت کسب امتیاز کامل نیاز است تا پاسخ شما حداقل امتیاز <code>66</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e9984de",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " پیش‌بینی برای داده تست و خروجی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پس از مهندسی ویژگی و مدل‌سازی، الگوریتمی دارید که می‌تواند شما را از متغیرهای مستقل به متغیر هدف برساند.\n",
    "    <br>\n",
    "    از این مدل برای پیش‌بینی نمونه‌های موجود در مجموعه‌ی آزمون استفاده کنید و نتایج را در یک دیتافریم تک‌ستونه با نام <code>submission</code> و در قالب زیر آماده کنید. توجه داشته باشید که ترتیب پیش‌بینی شما اهمیت دارد یعنی به عنوان مثال پیش‌بینی مدل برای نمونه‌ی آزمون <code>m</code>ام را باید در ردیف <code>m</code>ام این دیتافریم ذخیره کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6d82d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div dir=rtl style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "|ستون|توضیحات|\n",
    "|:------:|:---:|\n",
    "|income|پیش‌بینی مدل شما (مقدار <code dir=ltr>>50K</code> یا <code dir=ltr><=50K</code>)|\n",
    "    \n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d4a0844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7164 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cancel\n",
       "0     <=50k\n",
       "1     <=50k\n",
       "2     <=50k\n",
       "3     <=50k\n",
       "4      >50k\n",
       "...     ...\n",
       "7159  <=50k\n",
       "7160  <=50k\n",
       "7161  <=50k\n",
       "7162  <=50k\n",
       "7163  <=50k\n",
       "\n",
       "[7164 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test samples\n",
    "prediction_t =clf.predict(test_data)\n",
    "submission = pd.DataFrame({'Cancel':prediction_t})\n",
    "submission=submission.replace({1: '>50k',0:'<=50k'})\n",
    "submission\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2d616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.875, 'x[7] <= 0.1\\ngini = 0.369\\nsamples = 19990\\nvalue = [15103, 4887]'),\n",
       " Text(0.25, 0.625, 'x[4] <= 0.7\\ngini = 0.495\\nsamples = 8125\\nvalue = [4452, 3673]'),\n",
       " Text(0.375, 0.75, 'True  '),\n",
       " Text(0.125, 0.375, 'x[10] <= 0.051\\ngini = 0.439\\nsamples = 5433\\nvalue = [3666.0, 1767.0]'),\n",
       " Text(0.0625, 0.125, 'gini = 0.413\\nsamples = 5163\\nvalue = [3660, 1503]'),\n",
       " Text(0.1875, 0.125, 'gini = 0.043\\nsamples = 270\\nvalue = [6, 264]'),\n",
       " Text(0.375, 0.375, 'x[10] <= 0.051\\ngini = 0.413\\nsamples = 2692\\nvalue = [786, 1906]'),\n",
       " Text(0.3125, 0.125, 'gini = 0.449\\nsamples = 2301\\nvalue = [784, 1517]'),\n",
       " Text(0.4375, 0.125, 'gini = 0.01\\nsamples = 391\\nvalue = [2, 389]'),\n",
       " Text(0.75, 0.625, 'x[10] <= 0.071\\ngini = 0.184\\nsamples = 11865\\nvalue = [10651, 1214]'),\n",
       " Text(0.625, 0.75, '  False'),\n",
       " Text(0.625, 0.375, 'x[7] <= 0.9\\ngini = 0.148\\nsamples = 11570\\nvalue = [10641.0, 929.0]'),\n",
       " Text(0.5625, 0.125, 'gini = 0.096\\nsamples = 10688\\nvalue = [10145, 543]'),\n",
       " Text(0.6875, 0.125, 'gini = 0.492\\nsamples = 882\\nvalue = [496, 386]'),\n",
       " Text(0.875, 0.375, 'x[0] <= 0.041\\ngini = 0.065\\nsamples = 295\\nvalue = [10, 285]'),\n",
       " Text(0.8125, 0.125, 'gini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(0.9375, 0.125, 'gini = 0.047\\nsamples = 291\\nvalue = [7, 284]')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15af33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using  the Package of H2o for creating Decisiontree model\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.frame import H2OFrame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "381d4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (3 months and 12 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 hour 51 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Tehran</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 12 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_USER_lvs0fw</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>900 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 hour 51 mins\n",
       "H2O_cluster_timezone:       Asia/Tehran\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    3 months and 12 days\n",
       "H2O_cluster_name:           H2O_from_python_USER_lvs0fw\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    900 Mb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.2 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">     age</th><th style=\"text-align: right;\">  workclass</th><th style=\"text-align: right;\">   fnlwgt</th><th style=\"text-align: right;\">  education</th><th style=\"text-align: right;\">  education.num</th><th style=\"text-align: right;\">  marital.status</th><th style=\"text-align: right;\">  occupation</th><th style=\"text-align: right;\">  relationship</th><th style=\"text-align: right;\">  race</th><th style=\"text-align: right;\">  sex</th><th style=\"text-align: right;\">  capital.gain</th><th style=\"text-align: right;\">  capital.loss</th><th style=\"text-align: right;\">  hours.per.week</th><th style=\"text-align: right;\">  native.country</th><th style=\"text-align: right;\">  income</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0.315068</td><td style=\"text-align: right;\">   0.714286</td><td style=\"text-align: right;\">0.143706 </td><td style=\"text-align: right;\">   0.933333</td><td style=\"text-align: right;\">       0.933333</td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.692308</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.704082</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.178082</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.0929307</td><td style=\"text-align: right;\">   0.733333</td><td style=\"text-align: right;\">       0.533333</td><td style=\"text-align: right;\">        0       </td><td style=\"text-align: right;\">    0.153846</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.39726 </td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.0658263</td><td style=\"text-align: right;\">   1       </td><td style=\"text-align: right;\">       0.6     </td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0       </td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.205479</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.147567 </td><td style=\"text-align: right;\">   0.533333</td><td style=\"text-align: right;\">       0.666667</td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.538462</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.602041</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.506849</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.0926176</td><td style=\"text-align: right;\">   0.866667</td><td style=\"text-align: right;\">       0       </td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.692308</td><td style=\"text-align: right;\">           1  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.615385</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.630137</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.0676967</td><td style=\"text-align: right;\">   1       </td><td style=\"text-align: right;\">       0.6     </td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.692308</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.153061</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.109589</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.132836 </td><td style=\"text-align: right;\">   0.333333</td><td style=\"text-align: right;\">       0.2     </td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.384615</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.615385</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.739726</td><td style=\"text-align: right;\">   0.142857</td><td style=\"text-align: right;\">0.147258 </td><td style=\"text-align: right;\">   0.733333</td><td style=\"text-align: right;\">       0.533333</td><td style=\"text-align: right;\">        1       </td><td style=\"text-align: right;\">    0.230769</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.326531</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.273973</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.0369467</td><td style=\"text-align: right;\">   0.733333</td><td style=\"text-align: right;\">       0.533333</td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.384615</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   1  </td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.369863</td><td style=\"text-align: right;\">   0.428571</td><td style=\"text-align: right;\">0.146096 </td><td style=\"text-align: right;\">   0.533333</td><td style=\"text-align: right;\">       0.666667</td><td style=\"text-align: right;\">        0.333333</td><td style=\"text-align: right;\">    0.230769</td><td style=\"text-align: right;\">           0  </td><td style=\"text-align: right;\">   0.5</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0.397959</td><td style=\"text-align: right;\">        0.948718</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[24988 rows x 15 columns]</pre>"
      ],
      "text/plain": [
       "     age    workclass     fnlwgt    education    education.num    marital.status    occupation    relationship    race    sex    capital.gain    capital.loss    hours.per.week    native.country    income\n",
       "--------  -----------  ---------  -----------  ---------------  ----------------  ------------  --------------  ------  -----  --------------  --------------  ----------------  ----------------  --------\n",
       "0.315068     0.714286  0.143706      0.933333         0.933333          0.333333      0.692308             0       1        1               1               0          0.704082          0.948718         1\n",
       "0.178082     0.428571  0.0929307     0.733333         0.533333          0             0.153846             0.2     1        0               0               0          0.397959          0.948718         0\n",
       "0.39726      0.428571  0.0658263     1                0.6               0.333333      0                    0       1        1               0               0          0.397959          0.948718         1\n",
       "0.205479     0.428571  0.147567      0.533333         0.666667          0.333333      0.538462             0       1        1               0               0          0.602041          0.948718         1\n",
       "0.506849     0.428571  0.0926176     0.866667         0                 0.333333      0.692308             1       1        0               0               0          0.397959          0.615385         0\n",
       "0.630137     0.428571  0.0676967     1                0.6               0.333333      0.692308             0       1        1               0               0          0.153061          0.948718         0\n",
       "0.109589     0.428571  0.132836      0.333333         0.2               0.333333      0.384615             0       1        1               0               0          0.397959          0.615385         0\n",
       "0.739726     0.142857  0.147258      0.733333         0.533333          1             0.230769             0.4     1        0               0               0          0.326531          0.948718         0\n",
       "0.273973     0.428571  0.0369467     0.733333         0.533333          0.333333      0.384615             0       1        1               0               0          0.397959          0.948718         0\n",
       "0.369863     0.428571  0.146096      0.533333         0.666667          0.333333      0.230769             0       0.5      1               0               0          0.397959          0.948718         0\n",
       "[24988 rows x 15 columns]\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.init()\n",
    "train_data_h2o=H2OFrame(train_data)\n",
    "test_data_h2o=H2OFrame(test_data)\n",
    "\n",
    "train_data_h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ee808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ORandomForestEstimator : Distributed Random Forest\n",
       "Model Key: DRF_model_python_1739555898218_68\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-56.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-56 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-56 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-56 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-56 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-56 .h2o-table th,\n",
       "#h2o-table-56 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-56 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-56\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th>\n",
       "<th>number_of_internal_trees</th>\n",
       "<th>model_size_in_bytes</th>\n",
       "<th>min_depth</th>\n",
       "<th>max_depth</th>\n",
       "<th>mean_depth</th>\n",
       "<th>min_leaves</th>\n",
       "<th>max_leaves</th>\n",
       "<th>mean_leaves</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4391.0</td>\n",
       "<td>10.0</td>\n",
       "<td>10.0</td>\n",
       "<td>10.0</td>\n",
       "<td>345.0</td>\n",
       "<td>345.0</td>\n",
       "<td>345.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: NaN\n",
       "RMSE: NaN\n",
       "LogLoss: NaN\n",
       "Mean Per-Class Error: NaN\n",
       "AUC: NaN\n",
       "AUCPR: NaN\n",
       "Gini: NaN</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.11012860747869678\n",
       "RMSE: 0.3318563054677382\n",
       "LogLoss: 0.5996675558042001\n",
       "Mean Per-Class Error: 0.1929865309408172\n",
       "AUC: 0.8882630116716377\n",
       "AUCPR: 0.7356383793552753\n",
       "Gini: 0.7765260233432754</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-57.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-57 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-57 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-57 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-57 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-57 .h2o-table th,\n",
       "#h2o-table-57 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-57 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-57\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.301369845867157</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>3006.0</td>\n",
       "<td>692.0</td>\n",
       "<td>0.1871</td>\n",
       "<td> (692.0/3698.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>241.0</td>\n",
       "<td>971.0</td>\n",
       "<td>0.1988</td>\n",
       "<td> (241.0/1212.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3247.0</td>\n",
       "<td>1663.0</td>\n",
       "<td>0.19</td>\n",
       "<td> (933.0/4910.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-58.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-58 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-58 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-58 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-58 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-58 .h2o-table th,\n",
       "#h2o-table-58 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-58 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-58\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3013698</td>\n",
       "<td>0.6754783</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.7771839</td>\n",
       "<td>55.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5827338</td>\n",
       "<td>0.7054883</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5827338</td>\n",
       "<td>0.8452138</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8823529</td>\n",
       "<td>0.9184549</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951325</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.5614825</td>\n",
       "<td>41.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3013698</td>\n",
       "<td>0.8011551</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1842105</td>\n",
       "<td>0.8156032</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0</td>\n",
       "<td>3680.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0</td>\n",
       "<td>1011.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0</td>\n",
       "<td>3698.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0</td>\n",
       "<td>1212.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951325</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8341584</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-59.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-59 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-59 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-59 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-59 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-59 .h2o-table th,\n",
       "#h2o-table-59 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-59 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-59\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.68 %, avg score: 24.66 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0446029</td>\n",
       "<td>1.0</td>\n",
       "<td>3.7181835</td>\n",
       "<td>3.7181835</td>\n",
       "<td>0.9178082</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9178082</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1658416</td>\n",
       "<td>0.1658416</td>\n",
       "<td>271.8183462</td>\n",
       "<td>271.8183462</td>\n",
       "<td>0.1609741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0859470</td>\n",
       "<td>0.8206896</td>\n",
       "<td>3.3925930</td>\n",
       "<td>3.5615605</td>\n",
       "<td>0.8374384</td>\n",
       "<td>0.8303296</td>\n",
       "<td>0.8791469</td>\n",
       "<td>0.9183813</td>\n",
       "<td>0.1402640</td>\n",
       "<td>0.3061056</td>\n",
       "<td>239.2592954</td>\n",
       "<td>256.1560540</td>\n",
       "<td>0.2923144</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.1517312</td>\n",
       "<td>0.7153629</td>\n",
       "<td>2.7216739</td>\n",
       "<td>3.1974218</td>\n",
       "<td>0.6718266</td>\n",
       "<td>0.7198407</td>\n",
       "<td>0.7892617</td>\n",
       "<td>0.8323026</td>\n",
       "<td>0.1790429</td>\n",
       "<td>0.4851485</td>\n",
       "<td>172.1673870</td>\n",
       "<td>219.7421756</td>\n",
       "<td>0.4426931</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.2309572</td>\n",
       "<td>0.4856614</td>\n",
       "<td>1.9474705</td>\n",
       "<td>2.7686466</td>\n",
       "<td>0.4807198</td>\n",
       "<td>0.5318334</td>\n",
       "<td>0.6834215</td>\n",
       "<td>0.7292316</td>\n",
       "<td>0.1542904</td>\n",
       "<td>0.6394389</td>\n",
       "<td>94.7470454</td>\n",
       "<td>176.8646574</td>\n",
       "<td>0.5423594</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.3291242</td>\n",
       "<td>0.3510119</td>\n",
       "<td>1.4876648</td>\n",
       "<td>2.3865716</td>\n",
       "<td>0.3672199</td>\n",
       "<td>0.3737605</td>\n",
       "<td>0.5891089</td>\n",
       "<td>0.6232062</td>\n",
       "<td>0.1460396</td>\n",
       "<td>0.7854785</td>\n",
       "<td>48.7664845</td>\n",
       "<td>138.6571578</td>\n",
       "<td>0.6059220</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.4287169</td>\n",
       "<td>0.1749644</td>\n",
       "<td>0.9858639</td>\n",
       "<td>2.0611815</td>\n",
       "<td>0.2433538</td>\n",
       "<td>0.2238991</td>\n",
       "<td>0.5087886</td>\n",
       "<td>0.5304455</td>\n",
       "<td>0.0981848</td>\n",
       "<td>0.8836634</td>\n",
       "<td>-1.4136076</td>\n",
       "<td>106.1181534</td>\n",
       "<td>0.6040528</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.5024440</td>\n",
       "<td>0.0930232</td>\n",
       "<td>0.6490801</td>\n",
       "<td>1.8539741</td>\n",
       "<td>0.1602210</td>\n",
       "<td>0.1323309</td>\n",
       "<td>0.4576409</td>\n",
       "<td>0.4720274</td>\n",
       "<td>0.0478548</td>\n",
       "<td>0.9315182</td>\n",
       "<td>-35.0919899</td>\n",
       "<td>85.3974108</td>\n",
       "<td>0.5697010</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.6010183</td>\n",
       "<td>0.0437158</td>\n",
       "<td>0.3599167</td>\n",
       "<td>1.6089305</td>\n",
       "<td>0.0888430</td>\n",
       "<td>0.0605648</td>\n",
       "<td>0.3971535</td>\n",
       "<td>0.4045425</td>\n",
       "<td>0.0354785</td>\n",
       "<td>0.9669967</td>\n",
       "<td>-64.0083327</td>\n",
       "<td>60.8930463</td>\n",
       "<td>0.4859259</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7018330</td>\n",
       "<td>0.0162162</td>\n",
       "<td>0.1227623</td>\n",
       "<td>1.3954501</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0294184</td>\n",
       "<td>0.3444573</td>\n",
       "<td>0.3506579</td>\n",
       "<td>0.0123762</td>\n",
       "<td>0.9793729</td>\n",
       "<td>-87.7237724</td>\n",
       "<td>39.5450122</td>\n",
       "<td>0.3685022</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0691796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0170765</td>\n",
       "<td>0.0018110</td>\n",
       "<td>0.2468432</td>\n",
       "<td>0.2466433</td>\n",
       "<td>0.0206271</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.0820439</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-60.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-60 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-60 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-60 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-60 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-60 .h2o-table th,\n",
       "#h2o-table-60 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-60 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-60\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-02-14 23:53:42</td>\n",
       "<td> 0.071 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-02-14 23:53:42</td>\n",
       "<td> 0.159 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>0.3318563</td>\n",
       "<td>0.5996676</td>\n",
       "<td>0.8882630</td>\n",
       "<td>0.7356384</td>\n",
       "<td>3.7181835</td>\n",
       "<td>0.1900204</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-61.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-61 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-61 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-61 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-61 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-61 .h2o-table th,\n",
       "#h2o-table-61 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-61 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-61\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>education.num</td>\n",
       "<td>475.9605713</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2746005</td></tr>\n",
       "<tr><td>marital.status</td>\n",
       "<td>278.1674805</td>\n",
       "<td>0.5844339</td>\n",
       "<td>0.1604858</td></tr>\n",
       "<tr><td>capital.gain</td>\n",
       "<td>271.0165405</td>\n",
       "<td>0.5694096</td>\n",
       "<td>0.1563602</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>173.2987061</td>\n",
       "<td>0.3641031</td>\n",
       "<td>0.0999829</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>141.6699524</td>\n",
       "<td>0.2976506</td>\n",
       "<td>0.0817350</td></tr>\n",
       "<tr><td>relationship</td>\n",
       "<td>139.6427612</td>\n",
       "<td>0.2933914</td>\n",
       "<td>0.0805654</td></tr>\n",
       "<tr><td>capital.loss</td>\n",
       "<td>89.2104111</td>\n",
       "<td>0.1874324</td>\n",
       "<td>0.0514690</td></tr>\n",
       "<tr><td>hours.per.week</td>\n",
       "<td>79.3076172</td>\n",
       "<td>0.1666264</td>\n",
       "<td>0.0457557</td></tr>\n",
       "<tr><td>occupation</td>\n",
       "<td>25.9340992</td>\n",
       "<td>0.0544879</td>\n",
       "<td>0.0149624</td></tr>\n",
       "<tr><td>education</td>\n",
       "<td>25.0138969</td>\n",
       "<td>0.0525546</td>\n",
       "<td>0.0144315</td></tr>\n",
       "<tr><td>fnlwgt</td>\n",
       "<td>13.0601950</td>\n",
       "<td>0.0274397</td>\n",
       "<td>0.0075349</td></tr>\n",
       "<tr><td>workclass</td>\n",
       "<td>11.3339071</td>\n",
       "<td>0.0238127</td>\n",
       "<td>0.0065390</td></tr>\n",
       "<tr><td>race</td>\n",
       "<td>8.6881819</td>\n",
       "<td>0.0182540</td>\n",
       "<td>0.0050126</td></tr>\n",
       "<tr><td>native.country</td>\n",
       "<td>0.9792646</td>\n",
       "<td>0.0020574</td>\n",
       "<td>0.0005650</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ORandomForestEstimator : Distributed Random Forest\n",
       "Model Key: DRF_model_python_1739555898218_68\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    1                  1                           4391                   10           10           10            345           345           345\n",
       "\n",
       "ModelMetricsBinomial: drf\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: NaN\n",
       "RMSE: NaN\n",
       "LogLoss: NaN\n",
       "Mean Per-Class Error: NaN\n",
       "AUC: NaN\n",
       "AUCPR: NaN\n",
       "Gini: NaN\n",
       "\n",
       "ModelMetricsBinomial: drf\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.11012860747869678\n",
       "RMSE: 0.3318563054677382\n",
       "LogLoss: 0.5996675558042001\n",
       "Mean Per-Class Error: 0.1929865309408172\n",
       "AUC: 0.8882630116716377\n",
       "AUCPR: 0.7356383793552753\n",
       "Gini: 0.7765260233432754\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.301369845867157\n",
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  --------------\n",
       "0      3006  692   0.1871   (692.0/3698.0)\n",
       "1      241   971   0.1988   (241.0/1212.0)\n",
       "Total  3247  1663  0.19     (933.0/4910.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.30137      0.675478  35\n",
       "max f2                       0.142857     0.777184  55\n",
       "max f0point5                 0.582734     0.705488  17\n",
       "max accuracy                 0.582734     0.845214  17\n",
       "max precision                0.882353     0.918455  4\n",
       "max recall                   0            1         99\n",
       "max specificity              1            0.995133  0\n",
       "max absolute_mcc             0.212121     0.561482  41\n",
       "max min_per_class_accuracy   0.30137      0.801155  35\n",
       "max mean_per_class_accuracy  0.184211     0.815603  44\n",
       "max tns                      1            3680      0\n",
       "max fns                      1            1011      0\n",
       "max fps                      0            3698      99\n",
       "max tps                      0            1212      99\n",
       "max tnr                      1            0.995133  0\n",
       "max fnr                      1            0.834158  0\n",
       "max fpr                      0            1         99\n",
       "max tpr                      0            1         99\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.68 %, avg score: 24.66 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0446029                   1                  3.71818    3.71818            0.917808         1           0.917808                    1                   0.165842        0.165842                   271.818   271.818            0.160974\n",
       "2        0.085947                    0.82069            3.39259    3.56156            0.837438         0.83033     0.879147                    0.918381            0.140264        0.306106                   239.259   256.156            0.292314\n",
       "3        0.151731                    0.715363           2.72167    3.19742            0.671827         0.719841    0.789262                    0.832303            0.179043        0.485149                   172.167   219.742            0.442693\n",
       "4        0.230957                    0.485661           1.94747    2.76865            0.48072          0.531833    0.683422                    0.729232            0.15429         0.639439                   94.747    176.865            0.542359\n",
       "5        0.329124                    0.351012           1.48766    2.38657            0.36722          0.373761    0.589109                    0.623206            0.14604         0.785479                   48.7665   138.657            0.605922\n",
       "6        0.428717                    0.174964           0.985864   2.06118            0.243354         0.223899    0.508789                    0.530446            0.0981848       0.883663                   -1.41361  106.118            0.604053\n",
       "7        0.502444                    0.0930232          0.64908    1.85397            0.160221         0.132331    0.457641                    0.472027            0.0478548       0.931518                   -35.092   85.3974            0.569701\n",
       "8        0.601018                    0.0437158          0.359917   1.60893            0.088843         0.0605648   0.397154                    0.404543            0.0354785       0.966997                   -64.0083  60.893             0.485926\n",
       "9        0.701833                    0.0162162          0.122762   1.39545            0.030303         0.0294184   0.344457                    0.350658            0.0123762       0.979373                   -87.7238  39.545             0.368502\n",
       "10       1                           0                  0.0691796  1                  0.0170765        0.00181101  0.246843                    0.246643            0.0206271       1                          -93.082   0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-02-14 23:53:42  0.071 sec   0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2025-02-14 23:53:42  0.159 sec   1                  nan              nan                 nan             nan                nan              nan                              0.331856           0.599668              0.888263          0.735638             3.71818            0.19002\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "education.num   475.961                1                    0.274601\n",
       "marital.status  278.167                0.584434             0.160486\n",
       "capital.gain    271.017                0.56941              0.15636\n",
       "sex             173.299                0.364103             0.0999829\n",
       "age             141.67                 0.297651             0.081735\n",
       "relationship    139.643                0.293391             0.0805654\n",
       "capital.loss    89.2104                0.187432             0.051469\n",
       "hours.per.week  79.3076                0.166626             0.0457557\n",
       "occupation      25.9341                0.0544879            0.0149624\n",
       "education       25.0139                0.0525546            0.0144315\n",
       "fnlwgt          13.0602                0.0274397            0.00753494\n",
       "workclass       11.3339                0.0238127            0.00653898\n",
       "race            8.68818                0.018254             0.00501256\n",
       "native.country  0.979265               0.00205745           0.000564977\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training and evaluateing model(H2o_RandomForest)\n",
    "\n",
    "train_data_h2o['income']=train_data_h2o['income'].asfactor()  #Changing type of  column'income' from numerical to categorical fromat(H2o) \n",
    "\n",
    "#split train_data_h2o\n",
    "train, valid=train_data_h2o.split_frame(ratios=[0.8],seed=42)\n",
    "x_features=train.columns[:-1]\n",
    "y_target='income'\n",
    "\n",
    "#creating Model\n",
    "model=H2ORandomForestEstimator(ntrees=1,max_depth=10,mtries=-1,sample_rate=1,seed=42)\n",
    "model.train(x=x_features,y='income',training_frame=train,validation_frame=valid)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68170d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.11012860747869678\n",
       "RMSE: 0.3318563054677382\n",
       "LogLoss: 0.5996675558042001\n",
       "Mean Per-Class Error: 0.1929865309408172\n",
       "AUC: 0.8882630116716377\n",
       "AUCPR: 0.7356383793552753\n",
       "Gini: 0.7765260233432754</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-65.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-65 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-65 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-65 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-65 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-65 .h2o-table th,\n",
       "#h2o-table-65 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-65 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-65\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.301369845867157</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>3006.0</td>\n",
       "<td>692.0</td>\n",
       "<td>0.1871</td>\n",
       "<td> (692.0/3698.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>241.0</td>\n",
       "<td>971.0</td>\n",
       "<td>0.1988</td>\n",
       "<td> (241.0/1212.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>3247.0</td>\n",
       "<td>1663.0</td>\n",
       "<td>0.19</td>\n",
       "<td> (933.0/4910.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-66.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-66 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-66 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-66 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-66 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-66 .h2o-table th,\n",
       "#h2o-table-66 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-66 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-66\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3013698</td>\n",
       "<td>0.6754783</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.7771839</td>\n",
       "<td>55.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5827338</td>\n",
       "<td>0.7054883</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5827338</td>\n",
       "<td>0.8452138</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8823529</td>\n",
       "<td>0.9184549</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951325</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.5614825</td>\n",
       "<td>41.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3013698</td>\n",
       "<td>0.8011551</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1842105</td>\n",
       "<td>0.8156032</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0</td>\n",
       "<td>3680.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0</td>\n",
       "<td>1011.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0</td>\n",
       "<td>3698.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0</td>\n",
       "<td>1212.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951325</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8341584</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-67.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-67 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-67 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-67 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-67 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-67 .h2o-table th,\n",
       "#h2o-table-67 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-67 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-67\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.68 %, avg score: 24.66 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0446029</td>\n",
       "<td>1.0</td>\n",
       "<td>3.7181835</td>\n",
       "<td>3.7181835</td>\n",
       "<td>0.9178082</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9178082</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1658416</td>\n",
       "<td>0.1658416</td>\n",
       "<td>271.8183462</td>\n",
       "<td>271.8183462</td>\n",
       "<td>0.1609741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0859470</td>\n",
       "<td>0.8206896</td>\n",
       "<td>3.3925930</td>\n",
       "<td>3.5615605</td>\n",
       "<td>0.8374384</td>\n",
       "<td>0.8303296</td>\n",
       "<td>0.8791469</td>\n",
       "<td>0.9183813</td>\n",
       "<td>0.1402640</td>\n",
       "<td>0.3061056</td>\n",
       "<td>239.2592954</td>\n",
       "<td>256.1560540</td>\n",
       "<td>0.2923144</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.1517312</td>\n",
       "<td>0.7153629</td>\n",
       "<td>2.7216739</td>\n",
       "<td>3.1974218</td>\n",
       "<td>0.6718266</td>\n",
       "<td>0.7198407</td>\n",
       "<td>0.7892617</td>\n",
       "<td>0.8323026</td>\n",
       "<td>0.1790429</td>\n",
       "<td>0.4851485</td>\n",
       "<td>172.1673870</td>\n",
       "<td>219.7421756</td>\n",
       "<td>0.4426931</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.2309572</td>\n",
       "<td>0.4856614</td>\n",
       "<td>1.9474705</td>\n",
       "<td>2.7686466</td>\n",
       "<td>0.4807198</td>\n",
       "<td>0.5318334</td>\n",
       "<td>0.6834215</td>\n",
       "<td>0.7292316</td>\n",
       "<td>0.1542904</td>\n",
       "<td>0.6394389</td>\n",
       "<td>94.7470454</td>\n",
       "<td>176.8646574</td>\n",
       "<td>0.5423594</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.3291242</td>\n",
       "<td>0.3510119</td>\n",
       "<td>1.4876648</td>\n",
       "<td>2.3865716</td>\n",
       "<td>0.3672199</td>\n",
       "<td>0.3737605</td>\n",
       "<td>0.5891089</td>\n",
       "<td>0.6232062</td>\n",
       "<td>0.1460396</td>\n",
       "<td>0.7854785</td>\n",
       "<td>48.7664845</td>\n",
       "<td>138.6571578</td>\n",
       "<td>0.6059220</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.4287169</td>\n",
       "<td>0.1749644</td>\n",
       "<td>0.9858639</td>\n",
       "<td>2.0611815</td>\n",
       "<td>0.2433538</td>\n",
       "<td>0.2238991</td>\n",
       "<td>0.5087886</td>\n",
       "<td>0.5304455</td>\n",
       "<td>0.0981848</td>\n",
       "<td>0.8836634</td>\n",
       "<td>-1.4136076</td>\n",
       "<td>106.1181534</td>\n",
       "<td>0.6040528</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.5024440</td>\n",
       "<td>0.0930232</td>\n",
       "<td>0.6490801</td>\n",
       "<td>1.8539741</td>\n",
       "<td>0.1602210</td>\n",
       "<td>0.1323309</td>\n",
       "<td>0.4576409</td>\n",
       "<td>0.4720274</td>\n",
       "<td>0.0478548</td>\n",
       "<td>0.9315182</td>\n",
       "<td>-35.0919899</td>\n",
       "<td>85.3974108</td>\n",
       "<td>0.5697010</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.6010183</td>\n",
       "<td>0.0437158</td>\n",
       "<td>0.3599167</td>\n",
       "<td>1.6089305</td>\n",
       "<td>0.0888430</td>\n",
       "<td>0.0605648</td>\n",
       "<td>0.3971535</td>\n",
       "<td>0.4045425</td>\n",
       "<td>0.0354785</td>\n",
       "<td>0.9669967</td>\n",
       "<td>-64.0083327</td>\n",
       "<td>60.8930463</td>\n",
       "<td>0.4859259</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7018330</td>\n",
       "<td>0.0162162</td>\n",
       "<td>0.1227623</td>\n",
       "<td>1.3954501</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0294184</td>\n",
       "<td>0.3444573</td>\n",
       "<td>0.3506579</td>\n",
       "<td>0.0123762</td>\n",
       "<td>0.9793729</td>\n",
       "<td>-87.7237724</td>\n",
       "<td>39.5450122</td>\n",
       "<td>0.3685022</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0691796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0170765</td>\n",
       "<td>0.0018110</td>\n",
       "<td>0.2468432</td>\n",
       "<td>0.2466433</td>\n",
       "<td>0.0206271</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.0820439</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomial: drf\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.11012860747869678\n",
       "RMSE: 0.3318563054677382\n",
       "LogLoss: 0.5996675558042001\n",
       "Mean Per-Class Error: 0.1929865309408172\n",
       "AUC: 0.8882630116716377\n",
       "AUCPR: 0.7356383793552753\n",
       "Gini: 0.7765260233432754\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.301369845867157\n",
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  --------------\n",
       "0      3006  692   0.1871   (692.0/3698.0)\n",
       "1      241   971   0.1988   (241.0/1212.0)\n",
       "Total  3247  1663  0.19     (933.0/4910.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.30137      0.675478  35\n",
       "max f2                       0.142857     0.777184  55\n",
       "max f0point5                 0.582734     0.705488  17\n",
       "max accuracy                 0.582734     0.845214  17\n",
       "max precision                0.882353     0.918455  4\n",
       "max recall                   0            1         99\n",
       "max specificity              1            0.995133  0\n",
       "max absolute_mcc             0.212121     0.561482  41\n",
       "max min_per_class_accuracy   0.30137      0.801155  35\n",
       "max mean_per_class_accuracy  0.184211     0.815603  44\n",
       "max tns                      1            3680      0\n",
       "max fns                      1            1011      0\n",
       "max fps                      0            3698      99\n",
       "max tps                      0            1212      99\n",
       "max tnr                      1            0.995133  0\n",
       "max fnr                      1            0.834158  0\n",
       "max fpr                      0            1         99\n",
       "max tpr                      0            1         99\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.68 %, avg score: 24.66 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0446029                   1                  3.71818    3.71818            0.917808         1           0.917808                    1                   0.165842        0.165842                   271.818   271.818            0.160974\n",
       "2        0.085947                    0.82069            3.39259    3.56156            0.837438         0.83033     0.879147                    0.918381            0.140264        0.306106                   239.259   256.156            0.292314\n",
       "3        0.151731                    0.715363           2.72167    3.19742            0.671827         0.719841    0.789262                    0.832303            0.179043        0.485149                   172.167   219.742            0.442693\n",
       "4        0.230957                    0.485661           1.94747    2.76865            0.48072          0.531833    0.683422                    0.729232            0.15429         0.639439                   94.747    176.865            0.542359\n",
       "5        0.329124                    0.351012           1.48766    2.38657            0.36722          0.373761    0.589109                    0.623206            0.14604         0.785479                   48.7665   138.657            0.605922\n",
       "6        0.428717                    0.174964           0.985864   2.06118            0.243354         0.223899    0.508789                    0.530446            0.0981848       0.883663                   -1.41361  106.118            0.604053\n",
       "7        0.502444                    0.0930232          0.64908    1.85397            0.160221         0.132331    0.457641                    0.472027            0.0478548       0.931518                   -35.092   85.3974            0.569701\n",
       "8        0.601018                    0.0437158          0.359917   1.60893            0.088843         0.0605648   0.397154                    0.404543            0.0354785       0.966997                   -64.0083  60.893             0.485926\n",
       "9        0.701833                    0.0162162          0.122762   1.39545            0.030303         0.0294184   0.344457                    0.350658            0.0123762       0.979373                   -87.7238  39.545             0.368502\n",
       "10       1                           0                  0.0691796  1                  0.0170765        0.00181101  0.246843                    0.246643            0.0206271       1                          -93.082   0                  0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking model Performans for validation data\n",
    "model_performance_valid=model.model_performance(valid)\n",
    "model_performance_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cb04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: drf\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.0964418334332412\n",
       "RMSE: 0.3105508548261318\n",
       "LogLoss: 0.2985758810365306\n",
       "Mean Per-Class Error: 0.1724293128775961\n",
       "AUC: 0.9159518742666253\n",
       "AUCPR: 0.7923453009377907\n",
       "Gini: 0.8319037485332506</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-68.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-68 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-68 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-68 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-68 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-68 .h2o-table th,\n",
       "#h2o-table-68 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-68 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-68\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35101187229156494</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>12754.0</td>\n",
       "<td>2491.0</td>\n",
       "<td>0.1634</td>\n",
       "<td> (2491.0/15245.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>877.0</td>\n",
       "<td>3956.0</td>\n",
       "<td>0.1815</td>\n",
       "<td> (877.0/4833.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>13631.0</td>\n",
       "<td>6447.0</td>\n",
       "<td>0.1677</td>\n",
       "<td> (3368.0/20078.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-69.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-69 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-69 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-69 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-69 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-69 .h2o-table th,\n",
       "#h2o-table-69 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-69 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-69\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3510119</td>\n",
       "<td>0.7014184</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.7955595</td>\n",
       "<td>54.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6000000</td>\n",
       "<td>0.7374195</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5500000</td>\n",
       "<td>0.8593485</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0034904</td>\n",
       "<td>1.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4133334</td>\n",
       "<td>0.6053484</td>\n",
       "<td>30.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3035714</td>\n",
       "<td>0.8282640</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8335233</td>\n",
       "<td>40.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0</td>\n",
       "<td>15245.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0</td>\n",
       "<td>4031.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0</td>\n",
       "<td>15245.0</td>\n",
       "<td>101.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0034904</td>\n",
       "<td>4833.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8340575</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>101.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0034904</td>\n",
       "<td>1.0</td>\n",
       "<td>100.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-70.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-70 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-70 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-70 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-70 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-70 .h2o-table th,\n",
       "#h2o-table-70 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-70 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-70\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 24.07 %, avg score: 24.07 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0399442</td>\n",
       "<td>1.0</td>\n",
       "<td>4.1543555</td>\n",
       "<td>4.1543555</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1659425</td>\n",
       "<td>0.1659425</td>\n",
       "<td>315.4355473</td>\n",
       "<td>315.4355473</td>\n",
       "<td>0.1659425</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0408905</td>\n",
       "<td>0.9473684</td>\n",
       "<td>3.9357052</td>\n",
       "<td>4.1492954</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.9987820</td>\n",
       "<td>0.9987820</td>\n",
       "<td>0.0037244</td>\n",
       "<td>0.1696669</td>\n",
       "<td>293.5705185</td>\n",
       "<td>314.9295357</td>\n",
       "<td>0.1696013</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0833748</td>\n",
       "<td>0.8206896</td>\n",
       "<td>3.4530340</td>\n",
       "<td>3.7945099</td>\n",
       "<td>0.8311841</td>\n",
       "<td>0.8311841</td>\n",
       "<td>0.9133811</td>\n",
       "<td>0.9133811</td>\n",
       "<td>0.1466998</td>\n",
       "<td>0.3163666</td>\n",
       "<td>245.3034033</td>\n",
       "<td>279.4509867</td>\n",
       "<td>0.3068553</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.1403526</td>\n",
       "<td>0.7153629</td>\n",
       "<td>2.9886666</td>\n",
       "<td>3.4673684</td>\n",
       "<td>0.7194056</td>\n",
       "<td>0.7194056</td>\n",
       "<td>0.8346345</td>\n",
       "<td>0.8346345</td>\n",
       "<td>0.1702876</td>\n",
       "<td>0.4866543</td>\n",
       "<td>198.8666568</td>\n",
       "<td>246.7368372</td>\n",
       "<td>0.4560869</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1500647</td>\n",
       "<td>0.6666667</td>\n",
       "<td>2.8334835</td>\n",
       "<td>3.4263436</td>\n",
       "<td>0.6820513</td>\n",
       "<td>0.6820513</td>\n",
       "<td>0.8247594</td>\n",
       "<td>0.8247594</td>\n",
       "<td>0.0275191</td>\n",
       "<td>0.5141734</td>\n",
       "<td>183.3483476</td>\n",
       "<td>242.6343628</td>\n",
       "<td>0.4795391</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.2195438</td>\n",
       "<td>0.4856614</td>\n",
       "<td>2.1084471</td>\n",
       "<td>3.0092688</td>\n",
       "<td>0.5075269</td>\n",
       "<td>0.5075269</td>\n",
       "<td>0.7243648</td>\n",
       "<td>0.7243648</td>\n",
       "<td>0.1464929</td>\n",
       "<td>0.6606663</td>\n",
       "<td>110.8447079</td>\n",
       "<td>200.9268835</td>\n",
       "<td>0.5809680</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.3210977</td>\n",
       "<td>0.3510119</td>\n",
       "<td>1.5545725</td>\n",
       "<td>2.5491904</td>\n",
       "<td>0.3742030</td>\n",
       "<td>0.3742030</td>\n",
       "<td>0.6136187</td>\n",
       "<td>0.6136187</td>\n",
       "<td>0.1578730</td>\n",
       "<td>0.8185392</td>\n",
       "<td>55.4572450</td>\n",
       "<td>154.9190360</td>\n",
       "<td>0.6551414</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.4327124</td>\n",
       "<td>0.1749644</td>\n",
       "<td>0.9287515</td>\n",
       "<td>2.1312111</td>\n",
       "<td>0.2235609</td>\n",
       "<td>0.2235609</td>\n",
       "<td>0.5130064</td>\n",
       "<td>0.5130064</td>\n",
       "<td>0.1036623</td>\n",
       "<td>0.9222015</td>\n",
       "<td>-7.1248509</td>\n",
       "<td>113.1211135</td>\n",
       "<td>0.6446679</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.5008965</td>\n",
       "<td>0.1071429</td>\n",
       "<td>0.5492610</td>\n",
       "<td>1.9158696</td>\n",
       "<td>0.1322133</td>\n",
       "<td>0.1322133</td>\n",
       "<td>0.4611713</td>\n",
       "<td>0.4611713</td>\n",
       "<td>0.0374509</td>\n",
       "<td>0.9596524</td>\n",
       "<td>-45.0738977</td>\n",
       "<td>91.5869611</td>\n",
       "<td>0.6041916</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.6053392</td>\n",
       "<td>0.0437158</td>\n",
       "<td>0.2456557</td>\n",
       "<td>1.6276979</td>\n",
       "<td>0.0591321</td>\n",
       "<td>0.0591321</td>\n",
       "<td>0.3918052</td>\n",
       "<td>0.3918052</td>\n",
       "<td>0.0256569</td>\n",
       "<td>0.9853093</td>\n",
       "<td>-75.4344264</td>\n",
       "<td>62.7697940</td>\n",
       "<td>0.5004290</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.7073414</td>\n",
       "<td>0.0162162</td>\n",
       "<td>0.1217096</td>\n",
       "<td>1.4105268</td>\n",
       "<td>0.0292969</td>\n",
       "<td>0.0292969</td>\n",
       "<td>0.3395296</td>\n",
       "<td>0.3395296</td>\n",
       "<td>0.0124146</td>\n",
       "<td>0.9977240</td>\n",
       "<td>-87.8290367</td>\n",
       "<td>41.0526834</td>\n",
       "<td>0.3824403</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.8000299</td>\n",
       "<td>0.0034904</td>\n",
       "<td>0.0245556</td>\n",
       "<td>1.2499533</td>\n",
       "<td>0.0059108</td>\n",
       "<td>0.0059108</td>\n",
       "<td>0.3008778</td>\n",
       "<td>0.3008778</td>\n",
       "<td>0.0022760</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.5444433</td>\n",
       "<td>24.9953309</td>\n",
       "<td>0.2633650</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2407112</td>\n",
       "<td>0.2407112</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomial: drf\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.0964418334332412\n",
       "RMSE: 0.3105508548261318\n",
       "LogLoss: 0.2985758810365306\n",
       "Mean Per-Class Error: 0.1724293128775961\n",
       "AUC: 0.9159518742666253\n",
       "AUCPR: 0.7923453009377907\n",
       "Gini: 0.8319037485332506\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35101187229156494\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      12754  2491  0.1634   (2491.0/15245.0)\n",
       "1      877    3956  0.1815   (877.0/4833.0)\n",
       "Total  13631  6447  0.1677   (3368.0/20078.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.351012     0.701418  32\n",
       "max f2                       0.166667     0.79556   54\n",
       "max f0point5                 0.6          0.737419  18\n",
       "max accuracy                 0.55         0.859349  21\n",
       "max precision                1            1         0\n",
       "max recall                   0.00349039   1         100\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.413333     0.605348  30\n",
       "max min_per_class_accuracy   0.303571     0.828264  36\n",
       "max mean_per_class_accuracy  0.25         0.833523  40\n",
       "max tns                      1            15245     0\n",
       "max fns                      1            4031      0\n",
       "max fps                      0            15245     101\n",
       "max tps                      0.00349039   4833      100\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.834058  0\n",
       "max fpr                      0            1         101\n",
       "max tpr                      0.00349039   1         100\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 24.07 %, avg score: 24.07 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0399442                   1                  4.15436    4.15436            1                1           1                           1                   0.165942        0.165942                   315.436   315.436            0.165942\n",
       "2        0.0408905                   0.947368           3.93571    4.1493             0.947368         0.947368    0.998782                    0.998782            0.00372439      0.169667                   293.571   314.93             0.169601\n",
       "3        0.0833748                   0.82069            3.45303    3.79451            0.831184         0.831184    0.913381                    0.913381            0.1467          0.316367                   245.303   279.451            0.306855\n",
       "4        0.140353                    0.715363           2.98867    3.46737            0.719406         0.719406    0.834634                    0.834634            0.170288        0.486654                   198.867   246.737            0.456087\n",
       "5        0.150065                    0.666667           2.83348    3.42634            0.682051         0.682051    0.824759                    0.824759            0.0275191       0.514173                   183.348   242.634            0.479539\n",
       "6        0.219544                    0.485661           2.10845    3.00927            0.507527         0.507527    0.724365                    0.724365            0.146493        0.660666                   110.845   200.927            0.580968\n",
       "7        0.321098                    0.351012           1.55457    2.54919            0.374203         0.374203    0.613619                    0.613619            0.157873        0.818539                   55.4572   154.919            0.655141\n",
       "8        0.432712                    0.174964           0.928751   2.13121            0.223561         0.223561    0.513006                    0.513006            0.103662        0.922202                   -7.12485  113.121            0.644668\n",
       "9        0.500897                    0.107143           0.549261   1.91587            0.132213         0.132213    0.461171                    0.461171            0.0374509       0.959652                   -45.0739  91.587             0.604192\n",
       "10       0.605339                    0.0437158          0.245656   1.6277             0.0591321        0.0591321   0.391805                    0.391805            0.0256569       0.985309                   -75.4344  62.7698            0.500429\n",
       "11       0.707341                    0.0162162          0.12171    1.41053            0.0292969        0.0292969   0.33953                     0.33953             0.0124146       0.997724                   -87.829   41.0527            0.38244\n",
       "12       0.80003                     0.00349039         0.0245556  1.24995            0.0059108        0.00591079  0.300878                    0.300878            0.00227602      1                          -97.5444  24.9953            0.263365\n",
       "13       1                           0                  0          1                  0                0           0.240711                    0.240711            0               1                          -100      0                  0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking model Performans for train data\n",
    "model_performance_train=model.model_performance(train)\n",
    "model_performance_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.825036</td><td style=\"text-align: right;\">0.174964 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.855738</td><td style=\"text-align: right;\">0.144262 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.514339</td><td style=\"text-align: right;\">0.485661 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.935484</td><td style=\"text-align: right;\">0.0645161</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.764706</td><td style=\"text-align: right;\">0.235294 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.881553</td><td style=\"text-align: right;\">0.118447 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.956284</td><td style=\"text-align: right;\">0.0437158</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.696429</td><td style=\"text-align: right;\">0.303571 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1        </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[7164 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict        p0         p1\n",
       "---------  --------  ---------\n",
       "        0  0.825036  0.174964\n",
       "        0  0.855738  0.144262\n",
       "        1  0.514339  0.485661\n",
       "        0  0.935484  0.0645161\n",
       "        0  0.764706  0.235294\n",
       "        0  0.881553  0.118447\n",
       "        0  0.956284  0.0437158\n",
       "        1  0.696429  0.303571\n",
       "        1  0         1\n",
       "        1  0         1\n",
       "[7164 rows x 3 columns]\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predication\n",
    "prediction_t_h2o=model.predict(test_data_h2o)\n",
    "prediction_t_h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e7cd",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c3bcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['income.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "file_names = ['income.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d324736",
   "metadata": {},
   "source": [
    "<h4 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>راهنمایی</b>\n",
    "</font>\n",
    "</h4>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    ۱. توازن مجموعه‌داده را بررسی و مدیریت کنید.\n",
    "    <br>\n",
    "    ۲. برای مقادیر گم‌شده چه در هنگام آموزش و چه هنگام آزمون چاره‌ای بی‌اندیشید.\n",
    "    <br>\n",
    "    ۳. مقادیر گم‌شده ممکن است با عبارت دیگری به جز مقدار <code>NaN</code> نشان داده شده باشد.\n",
    "    <br>\n",
    "    ۴. ویژگی‌های دسته‌ای را به‌خوبی مدیریت کنید. توجه داشته باشید که ممکن است در هنگام آزمون با دسته‌ای مواجه شوید که در نمونه‌های آموزشی رخ نداده باشد.\n",
    "    <br>\n",
    "    ۵. برای تعیین حداکثر عمق درخت می‌توانید یکبار درخت را به شکل آزاد و کامل بسازید، سپس عمق آن را مشاهده کنید. سپس می‌توانید مقادیر کمتر از آن را برای حداکثر عمق آزمایش و تحلیل کنید.\n",
    "    <br>\n",
    "    ۶. برای ارزیابی مدل خود و کشف مدل بهتر می‌توانید بخشی از مجموعه‌داده را به عنوان مجموعه‌ی اعتبارسنجی جدا کنید یا اینکه از تکنیک‌های اعتبارسنجی متقاطع (cross-validation) و مانند آن کمک بگیرید.\n",
    "</font>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "qenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
